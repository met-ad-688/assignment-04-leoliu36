{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "title: Assignment 04\n",
        "subtitle: https://github.com/met-ad-688/assignment-04-leoliu36.git\n",
        "author:\n",
        "  - name: Leo Liu\n",
        "    affiliations:\n",
        "      - id: bu\n",
        "        name: Boston University\n",
        "        city: Boston\n",
        "        state: MA\n",
        "number-sections: true\n",
        "date: '2025-9-30'\n",
        "format:\n",
        "  docx:\n",
        "    toc: true\n",
        "    number-sections: true\n",
        "date-modified: today\n",
        "date-format: long\n",
        "execute:\n",
        "  echo: false\n",
        "  eval: true\n",
        "  freeze: auto\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: Using incubator modules: jdk.incubator.vector\n",
            "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
            "Setting default log level to \"WARN\".\n",
            "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
            "25/10/01 05:29:05 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
            "25/10/01 05:29:19 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
            "                                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+--------------------+-----------------+----------------------+----------+--------+---------+--------+--------------------+--------------------+--------------------+-----------+-------------------+--------------------+--------------------+---------------+----------------+--------+--------------------+-----------+-------------------+----------------+---------------------+-------------+-------------------+-------------+------------------+---------------+--------------------+--------------------+--------------------+-------------+------+-----------+----------------+-------------------+---------+-----------+--------------------+--------------------+-------------+------+--------------+-----+--------------------+-----+----------+---------------+--------------------+---------------+--------------------+------------+--------------------+------------+--------------------+------+--------------------+------+--------------------+------+--------------------+------+--------------------+------+--------------------+------------------+-------------------+--------------------+--------------------+--------------------+--------------------+-----------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+--------------------+----------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+--------------------+----------+--------------------+----------+---------------+----------+---------------+---------------+--------------------+--------------+--------------------+--------------------------+-------------------------------+--------------------+-------------------------+-----------------------------+----------------------------------+-----------------+----------------------+-----------------------+----------------------------+------------------+-----------------------+-------+--------------------+-------+--------------------+-------+---------------+-------+---------------+-----------------+----------------------+------------+--------------------+------------+--------------------+------------+--------------------+------------+--------------------+------------+--------------------+\n",
            "|                  ID|LAST_UPDATED_DATE|LAST_UPDATED_TIMESTAMP|DUPLICATES|  POSTED|  EXPIRED|DURATION|        SOURCE_TYPES|             SOURCES|                 URL|ACTIVE_URLS|ACTIVE_SOURCES_INFO|           TITLE_RAW|                BODY|MODELED_EXPIRED|MODELED_DURATION| COMPANY|        COMPANY_NAME|COMPANY_RAW|COMPANY_IS_STAFFING|EDUCATION_LEVELS|EDUCATION_LEVELS_NAME|MIN_EDULEVELS| MIN_EDULEVELS_NAME|MAX_EDULEVELS|MAX_EDULEVELS_NAME|EMPLOYMENT_TYPE|EMPLOYMENT_TYPE_NAME|MIN_YEARS_EXPERIENCE|MAX_YEARS_EXPERIENCE|IS_INTERNSHIP|SALARY|REMOTE_TYPE|REMOTE_TYPE_NAME|ORIGINAL_PAY_PERIOD|SALARY_TO|SALARY_FROM|            LOCATION|                CITY|    CITY_NAME|COUNTY|   COUNTY_NAME|  MSA|            MSA_NAME|STATE|STATE_NAME|COUNTY_OUTGOING|COUNTY_NAME_OUTGOING|COUNTY_INCOMING|COUNTY_NAME_INCOMING|MSA_OUTGOING|   MSA_NAME_OUTGOING|MSA_INCOMING|   MSA_NAME_INCOMING|NAICS2|         NAICS2_NAME|NAICS3|         NAICS3_NAME|NAICS4|         NAICS4_NAME|NAICS5|         NAICS5_NAME|NAICS6|         NAICS6_NAME|             TITLE|         TITLE_NAME|         TITLE_CLEAN|              SKILLS|         SKILLS_NAME|  SPECIALIZED_SKILLS|SPECIALIZED_SKILLS_NAME|      CERTIFICATIONS| CERTIFICATIONS_NAME|       COMMON_SKILLS|  COMMON_SKILLS_NAME|     SOFTWARE_SKILLS|SOFTWARE_SKILLS_NAME|      ONET|           ONET_NAME| ONET_2019|      ONET_2019_NAME|                CIP6|           CIP6_NAME|                CIP4|           CIP4_NAME|                CIP2|           CIP2_NAME|SOC_2021_2|     SOC_2021_2_NAME|SOC_2021_3|     SOC_2021_3_NAME|SOC_2021_4|SOC_2021_4_NAME|SOC_2021_5|SOC_2021_5_NAME|LOT_CAREER_AREA|LOT_CAREER_AREA_NAME|LOT_OCCUPATION| LOT_OCCUPATION_NAME|LOT_SPECIALIZED_OCCUPATION|LOT_SPECIALIZED_OCCUPATION_NAME|LOT_OCCUPATION_GROUP|LOT_OCCUPATION_GROUP_NAME|LOT_V6_SPECIALIZED_OCCUPATION|LOT_V6_SPECIALIZED_OCCUPATION_NAME|LOT_V6_OCCUPATION|LOT_V6_OCCUPATION_NAME|LOT_V6_OCCUPATION_GROUP|LOT_V6_OCCUPATION_GROUP_NAME|LOT_V6_CAREER_AREA|LOT_V6_CAREER_AREA_NAME|  SOC_2|          SOC_2_NAME|  SOC_3|          SOC_3_NAME|  SOC_4|     SOC_4_NAME|  SOC_5|     SOC_5_NAME|LIGHTCAST_SECTORS|LIGHTCAST_SECTORS_NAME|NAICS_2022_2|   NAICS_2022_2_NAME|NAICS_2022_3|   NAICS_2022_3_NAME|NAICS_2022_4|   NAICS_2022_4_NAME|NAICS_2022_5|   NAICS_2022_5_NAME|NAICS_2022_6|   NAICS_2022_6_NAME|\n",
            "+--------------------+-----------------+----------------------+----------+--------+---------+--------+--------------------+--------------------+--------------------+-----------+-------------------+--------------------+--------------------+---------------+----------------+--------+--------------------+-----------+-------------------+----------------+---------------------+-------------+-------------------+-------------+------------------+---------------+--------------------+--------------------+--------------------+-------------+------+-----------+----------------+-------------------+---------+-----------+--------------------+--------------------+-------------+------+--------------+-----+--------------------+-----+----------+---------------+--------------------+---------------+--------------------+------------+--------------------+------------+--------------------+------+--------------------+------+--------------------+------+--------------------+------+--------------------+------+--------------------+------------------+-------------------+--------------------+--------------------+--------------------+--------------------+-----------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+--------------------+----------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+--------------------+----------+--------------------+----------+---------------+----------+---------------+---------------+--------------------+--------------+--------------------+--------------------------+-------------------------------+--------------------+-------------------------+-----------------------------+----------------------------------+-----------------+----------------------+-----------------------+----------------------------+------------------+-----------------------+-------+--------------------+-------+--------------------+-------+---------------+-------+---------------+-----------------+----------------------+------------+--------------------+------------+--------------------+------------+--------------------+------------+--------------------+------------+--------------------+\n",
            "|1f57d95acf4dc67ed...|         9/6/2024|  2024-09-06 20:32:...|         0|6/2/2024| 6/8/2024|       6|   [\\n  \"Company\"\\n]|[\\n  \"brassring.c...|[\\n  \"https://sjo...|         []|               NULL|Enterprise Analys...|31-May-2024\\n\\nEn...|       6/8/2024|               6|  894731|          Murphy USA| Murphy USA|              false|       [\\n  2\\n]| [\\n  \"Bachelor's ...|            2|  Bachelor's degree|         NULL|              NULL|              1|Full-time (> 32 h...|                   2|                   2|        false|  NULL|          0|          [None]|               NULL|     NULL|       NULL|{\\n  \"lat\": 33.20...|RWwgRG9yYWRvLCBBUg==|El Dorado, AR|  5139|     Union, AR|20980|       El Dorado, AR|    5|  Arkansas|           5139|           Union, AR|           5139|           Union, AR|       20980|       El Dorado, AR|       20980|       El Dorado, AR|    44|        Retail Trade|   441|Motor Vehicle and...|  4413|Automotive Parts,...| 44133|Automotive Parts ...|441330|Automotive Parts ...|ET29C073C03D1F86B4|Enterprise Analysts|enterprise analys...|[\\n  \"KS126DB6T06...|[\\n  \"Merchandisi...|[\\n  \"KS126DB6T06...|   [\\n  \"Merchandisi...|                  []|                  []|[\\n  \"KS126706DPF...|[\\n  \"Mathematics...|[\\n  \"KS440W865GC...|[\\n  \"SQL (Progra...|15-2051.01|Business Intellig...|15-2051.01|Business Intellig...|[\\n  \"45.0601\",\\n...|[\\n  \"Economics, ...|[\\n  \"45.06\",\\n  ...|[\\n  \"Economics\",...|[\\n  \"45\",\\n  \"27...|[\\n  \"Social Scie...|   15-0000|Computer and Math...|   15-2000|Mathematical Scie...|   15-2050|Data Scientists|   15-2051|Data Scientists|             23|Information Techn...|        231010|Business Intellig...|                  23101011|           General ERP Analy...|                2310|     Business Intellig...|                     23101011|              General ERP Analy...|           231010|  Business Intellig...|                   2310|        Business Intellig...|                23|   Information Techn...|15-0000|Computer and Math...|15-2000|Mathematical Scie...|15-2050|Data Scientists|15-2051|Data Scientists|        [\\n  7\\n]|  [\\n  \"Artificial ...|          44|        Retail Trade|         441|Motor Vehicle and...|        4413|Automotive Parts,...|       44133|Automotive Parts ...|      441330|Automotive Parts ...|\n",
            "|0cb072af26757b6c4...|         8/2/2024|  2024-08-02 17:08:...|         0|6/2/2024| 8/1/2024|    NULL| [\\n  \"Job Board\"\\n]| [\\n  \"maine.gov\"\\n]|[\\n  \"https://job...|         []|               NULL|Oracle Consultant...|Oracle Consultant...|       8/1/2024|            NULL|  133098|Smx Corporation L...|        SMX|               true|      [\\n  99\\n]| [\\n  \"No Educatio...|           99|No Education Listed|         NULL|              NULL|              1|Full-time (> 32 h...|                   3|                   3|        false|  NULL|          1|          Remote|               NULL|     NULL|       NULL|{\\n  \"lat\": 44.31...|    QXVndXN0YSwgTUU=|  Augusta, ME| 23011|  Kennebec, ME|12300|Augusta-Watervill...|   23|     Maine|          23011|        Kennebec, ME|          23011|        Kennebec, ME|       12300|Augusta-Watervill...|       12300|Augusta-Watervill...|    56|Administrative an...|   561|Administrative an...|  5613| Employment Services| 56132|Temporary Help Se...|561320|Temporary Help Se...|ET21DDA63780A7DC09| Oracle Consultants|oracle consultant...|[\\n  \"KS122626T55...|[\\n  \"Procurement...|[\\n  \"KS122626T55...|   [\\n  \"Procurement...|                  []|                  []|                  []|                  []|[\\n  \"BGSBF3F508F...|[\\n  \"Oracle Busi...|15-2051.01|Business Intellig...|15-2051.01|Business Intellig...|                  []|                  []|                  []|                  []|                  []|                  []|   15-0000|Computer and Math...|   15-2000|Mathematical Scie...|   15-2050|Data Scientists|   15-2051|Data Scientists|             23|Information Techn...|        231010|Business Intellig...|                  23101012|           Oracle Consultant...|                2310|     Business Intellig...|                     23101012|              Oracle Consultant...|           231010|  Business Intellig...|                   2310|        Business Intellig...|                23|   Information Techn...|15-0000|Computer and Math...|15-2000|Mathematical Scie...|15-2050|Data Scientists|15-2051|Data Scientists|             NULL|                  NULL|          56|Administrative an...|         561|Administrative an...|        5613| Employment Services|       56132|Temporary Help Se...|      561320|Temporary Help Se...|\n",
            "|85318b12b3331fa49...|         9/6/2024|  2024-09-06 20:32:...|         1|6/2/2024| 7/7/2024|      35| [\\n  \"Job Board\"\\n]|[\\n  \"dejobs.org\"\\n]|[\\n  \"https://dej...|         []|               NULL|        Data Analyst|Taking care of pe...|      6/10/2024|               8|39063746|            Sedgwick|   Sedgwick|              false|       [\\n  2\\n]| [\\n  \"Bachelor's ...|            2|  Bachelor's degree|         NULL|              NULL|              1|Full-time (> 32 h...|                   5|                NULL|        false|  NULL|          0|          [None]|               NULL|     NULL|       NULL|{\\n  \"lat\": 32.77...|    RGFsbGFzLCBUWA==|   Dallas, TX| 48113|    Dallas, TX|19100|Dallas-Fort Worth...|   48|     Texas|          48113|          Dallas, TX|          48113|          Dallas, TX|       19100|Dallas-Fort Worth...|       19100|Dallas-Fort Worth...|    52|Finance and Insur...|   524|Insurance Carrier...|  5242|Agencies, Brokera...| 52429|Other Insurance R...|524291|    Claims Adjusting|ET3037E0C947A02404|      Data Analysts|        data analyst|[\\n  \"KS1218W78FG...|[\\n  \"Management\"...|[\\n  \"ESF3939CE1F...|   [\\n  \"Exception R...|[\\n  \"KS683TN76T7...|[\\n  \"Security Cl...|[\\n  \"KS1218W78FG...|[\\n  \"Management\"...|[\\n  \"KS126HY6YLT...|[\\n  \"Microsoft O...|15-2051.01|Business Intellig...|15-2051.01|Business Intellig...|                  []|                  []|                  []|                  []|                  []|                  []|   15-0000|Computer and Math...|   15-2000|Mathematical Scie...|   15-2050|Data Scientists|   15-2051|Data Scientists|             23|Information Techn...|        231113|Data / Data Minin...|                  23111310|                   Data Analyst|                2311|     Data Analysis and...|                     23111310|                      Data Analyst|           231113|  Data / Data Minin...|                   2311|        Data Analysis and...|                23|   Information Techn...|15-0000|Computer and Math...|15-2000|Mathematical Scie...|15-2050|Data Scientists|15-2051|Data Scientists|             NULL|                  NULL|          52|Finance and Insur...|         524|Insurance Carrier...|        5242|Agencies, Brokera...|       52429|Other Insurance R...|      524291|    Claims Adjusting|\n",
            "|1b5c3941e54a1889e...|         9/6/2024|  2024-09-06 20:32:...|         1|6/2/2024|7/20/2024|      48| [\\n  \"Job Board\"\\n]|[\\n  \"disabledper...|[\\n  \"https://www...|         []|               NULL|Sr. Lead Data Mgm...|About this role:\\...|      6/12/2024|              10|37615159|         Wells Fargo|Wells Fargo|              false|      [\\n  99\\n]| [\\n  \"No Educatio...|           99|No Education Listed|         NULL|              NULL|              1|Full-time (> 32 h...|                   3|                NULL|        false|  NULL|          0|          [None]|               NULL|     NULL|       NULL|{\\n  \"lat\": 33.44...|    UGhvZW5peCwgQVo=|  Phoenix, AZ|  4013|  Maricopa, AZ|38060|Phoenix-Mesa-Chan...|    4|   Arizona|           4013|        Maricopa, AZ|           4013|        Maricopa, AZ|       38060|Phoenix-Mesa-Chan...|       38060|Phoenix-Mesa-Chan...|    52|Finance and Insur...|   522|Credit Intermedia...|  5221|Depository Credit...| 52211|  Commercial Banking|522110|  Commercial Banking|ET2114E0404BA30075|Management Analysts|sr lead data mgmt...|[\\n  \"KS123QX62QY...|[\\n  \"Exit Strate...|[\\n  \"KS123QX62QY...|   [\\n  \"Exit Strate...|                  []|                  []|[\\n  \"KS7G6NP6R6L...|[\\n  \"Reliability...|[\\n  \"KS4409D76NW...|[\\n  \"SAS (Softwa...|15-2051.01|Business Intellig...|15-2051.01|Business Intellig...|                  []|                  []|                  []|                  []|                  []|                  []|   15-0000|Computer and Math...|   15-2000|Mathematical Scie...|   15-2050|Data Scientists|   15-2051|Data Scientists|             23|Information Techn...|        231113|Data / Data Minin...|                  23111310|                   Data Analyst|                2311|     Data Analysis and...|                     23111310|                      Data Analyst|           231113|  Data / Data Minin...|                   2311|        Data Analysis and...|                23|   Information Techn...|15-0000|Computer and Math...|15-2000|Mathematical Scie...|15-2050|Data Scientists|15-2051|Data Scientists|        [\\n  6\\n]|  [\\n  \"Data Privac...|          52|Finance and Insur...|         522|Credit Intermedia...|        5221|Depository Credit...|       52211|  Commercial Banking|      522110|  Commercial Banking|\n",
            "|cb5ca25f02bdf25c1...|        6/19/2024|   2024-06-19 07:00:00|         0|6/2/2024|6/17/2024|      15|[\\n  \"FreeJobBoar...|[\\n  \"craigslist....|[\\n  \"https://mod...|         []|               NULL|Comisiones de $10...|Comisiones de $10...|      6/17/2024|              15|       0|        Unclassified|      LH/GM|              false|      [\\n  99\\n]| [\\n  \"No Educatio...|           99|No Education Listed|         NULL|              NULL|              3|Part-time / full-...|                NULL|                NULL|        false| 92500|          0|          [None]|               year|   150000|      35000|{\\n  \"lat\": 37.63...|    TW9kZXN0bywgQ0E=|  Modesto, CA|  6099|Stanislaus, CA|33700|         Modesto, CA|    6|California|           6099|      Stanislaus, CA|           6099|      Stanislaus, CA|       33700|         Modesto, CA|       33700|         Modesto, CA|    99|Unclassified Indu...|   999|Unclassified Indu...|  9999|Unclassified Indu...| 99999|Unclassified Indu...|999999|Unclassified Indu...|ET0000000000000000|       Unclassified|comisiones de por...|                  []|                  []|                  []|                     []|                  []|                  []|                  []|                  []|                  []|                  []|15-2051.01|Business Intellig...|15-2051.01|Business Intellig...|                  []|                  []|                  []|                  []|                  []|                  []|   15-0000|Computer and Math...|   15-2000|Mathematical Scie...|   15-2050|Data Scientists|   15-2051|Data Scientists|             23|Information Techn...|        231010|Business Intellig...|                  23101012|           Oracle Consultant...|                2310|     Business Intellig...|                     23101012|              Oracle Consultant...|           231010|  Business Intellig...|                   2310|        Business Intellig...|                23|   Information Techn...|15-0000|Computer and Math...|15-2000|Mathematical Scie...|15-2050|Data Scientists|15-2051|Data Scientists|             NULL|                  NULL|          99|Unclassified Indu...|         999|Unclassified Indu...|        9999|Unclassified Indu...|       99999|Unclassified Indu...|      999999|Unclassified Indu...|\n",
            "+--------------------+-----------------+----------------------+----------+--------+---------+--------+--------------------+--------------------+--------------------+-----------+-------------------+--------------------+--------------------+---------------+----------------+--------+--------------------+-----------+-------------------+----------------+---------------------+-------------+-------------------+-------------+------------------+---------------+--------------------+--------------------+--------------------+-------------+------+-----------+----------------+-------------------+---------+-----------+--------------------+--------------------+-------------+------+--------------+-----+--------------------+-----+----------+---------------+--------------------+---------------+--------------------+------------+--------------------+------------+--------------------+------+--------------------+------+--------------------+------+--------------------+------+--------------------+------+--------------------+------------------+-------------------+--------------------+--------------------+--------------------+--------------------+-----------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+--------------------+----------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+--------------------+----------+--------------------+----------+---------------+----------+---------------+---------------+--------------------+--------------+--------------------+--------------------------+-------------------------------+--------------------+-------------------------+-----------------------------+----------------------------------+-----------------+----------------------+-----------------------+----------------------------+------------------+-----------------------+-------+--------------------+-------+--------------------+-------+---------------+-------+---------------+-----------------+----------------------+------------+--------------------+------------+--------------------+------------+--------------------+------------+--------------------+------------+--------------------+\n",
            "only showing top 5 rows\n"
          ]
        }
      ],
      "source": [
        "# Data Loading & Setup\n",
        "import pandas as pd\n",
        "import plotly.express as px\n",
        "import plotly.io as pio\n",
        "from pyspark.sql import SparkSession\n",
        "import re\n",
        "import numpy as np\n",
        "import plotly.graph_objects as go\n",
        "from pyspark.sql.functions import col, split, explode, regexp_replace, transform, when, trim, monotonically_increasing_id, pow, length, sum as spark_sum\n",
        "from pyspark.sql import functions as F\n",
        "from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.regression import LinearRegression\n",
        "\n",
        "np.random.seed(42)\n",
        "\n",
        "pio.renderers.default = \"notebook\"\n",
        "\n",
        "# Initialize Spark Session\n",
        "spark = SparkSession.builder.appName(\"LightcastData\").getOrCreate()\n",
        "\n",
        "# Load Data\n",
        "df = spark.read.option(\"header\", \"true\").option(\"inferSchema\", \"true\").option(\"multiLine\", \"true\").option(\"quote\", \"\\\"\").option(\"escape\", \"\\\"\").csv(\"../data/lightcast_job_postings.csv\")\n",
        "df.createOrReplaceTempView(\"job_postings\")\n",
        "\n",
        "# Show Schema and Sample Data\n",
        "#print(\"---This is Diagnostic check, No need to print it in the final doc---\")\n",
        "#df.printSchema() # comment this line when rendering the submission\n",
        "df.show(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Drop columns that are not needed for this analysis \n",
        "columns_to_drop = [\n",
        "  # tracking & other metadata\n",
        "    \"ID\", \"LAST_UPDATED_DATE\", \"LAST_UPDATED_TIMESTAMP\", \"DUPLICATES\",\n",
        "    \"SOURCE_TYPES\", \"SOURCES\", \"URL\", \"ACTIVE_URLS\", \"ACTIVE_SOURCES_INFO\", \"MODELED_EXPIRED\", \"MODELED_DURATION\", \"TITLE_RAW\", \"ORIGINAL_PAY_PERIOD\"\n",
        "  # outdated NAICS and SOC codes\n",
        "    \"NAICS2\", \"NAICS2_NAME\", \"NAICS3\", \"NAICS3_NAME\",\n",
        "    \"NAICS4\", \"NAICS4_NAME\", \"NAICS5\", \"NAICS5_NAME\",\n",
        "    \"NAICS6\", \"NAICS6_NAME\", \n",
        "    \"SOC_2\", \"SOC_2_NAME\", \"SOC_3\", \"SOC_3_NAME\",\n",
        "    \"SOC_4\", \"SOC_4_NAME\", \"SOC_5\", \"SOC_5_NAME\",\n",
        "    \"SOC_2021_2\", \"SOC_2021_2_NAME\", \"SOC_2021_3\", \"SOC_2021_3_NAME\",\n",
        "    \"SOC_2021_5\", \"SOC_2021_5_NAME\",\n",
        "    \"NAICS_2022_2\", \"NAICS_2022_2_NAME\", \"NAICS_2022_3\", \"NAICS_2022_3_NAME\",\n",
        "    \"NAICS_2022_4\", \"NAICS_2022_4_NAME\", \"NAICS_2022_5\", \"NAICS_2022_5_NAME\"\n",
        "  # Location encodings\n",
        "    \"COUNTY_OUTGOING\", \"COUNTY_NAME_OUTGOING\",\n",
        "    \"COUNTY_INCOMING\", \"COUNTY_NAME_INCOMING\",\n",
        "    \"MSA_OUTGOING\", \"MSA_NAME_OUTGOING\",\n",
        "    \"MSA_INCOMING\", \"MSA_NAME_INCOMING\"\n",
        "]\n",
        "\n",
        "# Drop columns \n",
        "df = df.drop(*columns_to_drop)\n",
        "\n",
        "# Show resulting schema\n",
        "df.printSchema()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+------+-----------+---------+--------------------+--------+-------------------+-------------+----------------+----------------------+-------------------+----------+\n",
            "|SALARY|SALARY_FROM|SALARY_TO|MIN_YEARS_EXPERIENCE|DURATION|COMPANY_IS_STAFFING|IS_INTERNSHIP|REMOTE_TYPE_NAME|EMPLOYMENT_TYPE_NAME  |MIN_EDULEVELS_NAME |STATE_NAME|\n",
            "+------+-----------+---------+--------------------+--------+-------------------+-------------+----------------+----------------------+-------------------+----------+\n",
            "|NULL  |NULL       |NULL     |2                   |6       |false              |false        |[None]          |Full-time (> 32 hours)|Bachelor's degree  |Arkansas  |\n",
            "|NULL  |NULL       |NULL     |3                   |NULL    |true               |false        |Remote          |Full-time (> 32 hours)|No Education Listed|Maine     |\n",
            "|NULL  |NULL       |NULL     |5                   |35      |false              |false        |[None]          |Full-time (> 32 hours)|Bachelor's degree  |Texas     |\n",
            "|NULL  |NULL       |NULL     |3                   |48      |false              |false        |[None]          |Full-time (> 32 hours)|No Education Listed|Arizona   |\n",
            "|92500 |35000      |150000   |NULL                |15      |false              |false        |[None]          |Part-time / full-time |No Education Listed|California|\n",
            "+------+-----------+---------+--------------------+--------+-------------------+-------------+----------------+----------------------+-------------------+----------+\n",
            "only showing top 5 rows\n"
          ]
        }
      ],
      "source": [
        "# Define columns for EDA: \n",
        "## dependent variable: SALARY\n",
        "## indepdendent variable: MIN_YEARS_EXPERIENCE, SALARY_FROM, SALARY_TO, DURATION \n",
        "## categorical variables: COMPANY_IS_STAFFING, IS_INTERNSHIP, REMOTE_TYPE_NAME, EMPLOYMENT_TYPE_NAME, MIN_EDULEVELS_NAME, MAX_EDULEVELS_NAME, STATE_NAME\n",
        "\n",
        "from pyspark.sql.functions import col, pow\n",
        "from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler\n",
        "from pyspark.ml import Pipeline\n",
        "\n",
        "eda_columns = [\n",
        "    \"SALARY\", \"SALARY_FROM\", \"SALARY_TO\",\n",
        "    \"MIN_YEARS_EXPERIENCE\", \"DURATION\",\n",
        "    \"COMPANY_IS_STAFFING\", \"IS_INTERNSHIP\", \"REMOTE_TYPE_NAME\", \"EMPLOYMENT_TYPE_NAME\",\n",
        "    \"MIN_EDULEVELS_NAME\", \"STATE_NAME\"\n",
        "]\n",
        "df_eda = df.select(eda_columns)\n",
        "df_eda.show(5, truncate=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pyspark.sql.functions import col, split, explode, regexp_replace, transform, when, trim, monotonically_increasing_id, pow, length, sum as spark_sum\n",
        "import hvplot.pandas\n",
        "\n",
        "# Visualize the percentage of missing values for each column\n",
        "df_na = df_eda.select([\n",
        "    spark_sum(\n",
        "        when(col(c).isNull() | (length(trim(col(c))) == 0), 1)\n",
        "    ).alias(c)\n",
        "    for c in df_eda.columns\n",
        "])\n",
        "\n",
        "df_na_pd = df_na.toPandas().T.reset_index()\n",
        "df_na_pd.columns = [\"column\", \"missing_count\"]\n",
        "\n",
        "total_rows = df.count()\n",
        "df_na_pd[\"missing_pct\"] = df_na_pd[\"missing_count\"] / total_rows * 100\n",
        "\n",
        "\n",
        "df_na_pd.sort_values(\"missing_pct\", ascending=False).hvplot.bar(\n",
        "    x=\"column\",\n",
        "    y=\"missing_pct\",\n",
        "    title=\"Percentage of Missing Values by Column\",\n",
        "    xlabel=\"Column Name\",\n",
        "    ylabel=\"Percentage of Missing Values\",\n",
        "    rot=45,\n",
        "    height=600,\n",
        "    width=1000\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import hvplot.pandas  # make sure this is imported for hvplot support\n",
        "\n",
        "# Sample a small fraction of the data and convert to Pandas\n",
        "df_sample = df_eda.sample(fraction=0.05, seed=42).toPandas()\n",
        "\n",
        "# Create a boolean mask of missing values\n",
        "missing_mask = df_sample.isnull()\n",
        "\n",
        "# Melt the mask into long-form format\n",
        "missing_long = (\n",
        "    missing_mask.reset_index()\n",
        "    .melt(id_vars=\"index\", var_name=\"column\", value_name=\"is_missing\")\n",
        ")\n",
        "\n",
        "# Convert boolean to int (True → 1, False → 0)\n",
        "missing_long[\"is_missing\"] = missing_long[\"is_missing\"].astype(int)\n",
        "\n",
        "missing_long[\"index\"] = missing_long[\"index\"].astype(str)\n",
        "missing_long[\"column\"] = missing_long[\"column\"].astype(str)\n",
        "missing_long[\"is_missing\"] = missing_long[\"is_missing\"].astype(int)\n",
        "\n",
        "# Plot heatmap\n",
        "missing_long.hvplot.heatmap(\n",
        "    x=\"column\", y=\"index\", C=\"is_missing\",\n",
        "    cmap=\"Reds\", colorbar=False,\n",
        "    width=900, height=700,\n",
        "    title=\"Heatmap of Missing Values (Sample)\"\n",
        ").opts(xrotation=45)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Stage 42:>                                                         (0 + 1) / 1]\r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+------+-----------+---------+--------------------+--------+-------------------+-------------+----------------+--------------------+------------------+----------+\n",
            "|SALARY|SALARY_FROM|SALARY_TO|MIN_YEARS_EXPERIENCE|DURATION|COMPANY_IS_STAFFING|IS_INTERNSHIP|REMOTE_TYPE_NAME|EMPLOYMENT_TYPE_NAME|MIN_EDULEVELS_NAME|STATE_NAME|\n",
            "+------+-----------+---------+--------------------+--------+-------------------+-------------+----------------+--------------------+------------------+----------+\n",
            "|6052  |4172       |4455     |16                  |60      |2                  |2            |4               |3                   |6                 |51        |\n",
            "+------+-----------+---------+--------------------+--------+-------------------+-------------+----------------+--------------------+------------------+----------+\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        }
      ],
      "source": [
        "from pyspark.sql.functions import countDistinct\n",
        "\n",
        "df_eda.select([countDistinct(col(c)).alias(c) for c in df_eda.columns]).show(truncate=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "---- REMOTE_TYPE_NAME ----\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+----------------+\n",
            "|REMOTE_TYPE_NAME|\n",
            "+----------------+\n",
            "|Remote          |\n",
            "|[None]          |\n",
            "|Not Remote      |\n",
            "|Hybrid Remote   |\n",
            "|NULL            |\n",
            "+----------------+\n",
            "\n",
            "\n",
            "---- COMPANY_IS_STAFFING ----\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-------------------+\n",
            "|COMPANY_IS_STAFFING|\n",
            "+-------------------+\n",
            "|true               |\n",
            "|false              |\n",
            "|NULL               |\n",
            "+-------------------+\n",
            "\n",
            "\n",
            "---- IS_INTERNSHIP ----\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-------------+\n",
            "|IS_INTERNSHIP|\n",
            "+-------------+\n",
            "|true         |\n",
            "|false        |\n",
            "|NULL         |\n",
            "+-------------+\n",
            "\n",
            "\n",
            "---- EMPLOYMENT_TYPE_NAME ----\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+------------------------+\n",
            "|EMPLOYMENT_TYPE_NAME    |\n",
            "+------------------------+\n",
            "|Part-time / full-time   |\n",
            "|Part-time (â‰¤ 32 hours)|\n",
            "|Full-time (> 32 hours)  |\n",
            "|NULL                    |\n",
            "+------------------------+\n",
            "\n",
            "\n",
            "---- MIN_EDULEVELS_NAME ----\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+----------------------------+\n",
            "|MIN_EDULEVELS_NAME          |\n",
            "+----------------------------+\n",
            "|Bachelor's degree           |\n",
            "|Ph.D. or professional degree|\n",
            "|High school or GED          |\n",
            "|Master's degree             |\n",
            "|No Education Listed         |\n",
            "|Associate degree            |\n",
            "|NULL                        |\n",
            "+----------------------------+\n",
            "\n",
            "\n",
            "---- STATE_NAME ----\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Stage 63:>                                                         (0 + 1) / 1]\r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---------------------------------------+\n",
            "|STATE_NAME                             |\n",
            "+---------------------------------------+\n",
            "|Utah                                   |\n",
            "|Hawaii                                 |\n",
            "|Minnesota                              |\n",
            "|Ohio                                   |\n",
            "|Arkansas                               |\n",
            "|Oregon                                 |\n",
            "|Texas                                  |\n",
            "|North Dakota                           |\n",
            "|Pennsylvania                           |\n",
            "|Connecticut                            |\n",
            "|Nebraska                               |\n",
            "|Vermont                                |\n",
            "|Nevada                                 |\n",
            "|Washington                             |\n",
            "|Illinois                               |\n",
            "|Oklahoma                               |\n",
            "|Delaware                               |\n",
            "|Alaska                                 |\n",
            "|New Mexico                             |\n",
            "|West Virginia                          |\n",
            "|Missouri                               |\n",
            "|Rhode Island                           |\n",
            "|Georgia                                |\n",
            "|Montana                                |\n",
            "|Michigan                               |\n",
            "|Virginia                               |\n",
            "|Washington, D.C. (District of Columbia)|\n",
            "|North Carolina                         |\n",
            "|Wyoming                                |\n",
            "|Kansas                                 |\n",
            "|New Jersey                             |\n",
            "|Maryland                               |\n",
            "|Alabama                                |\n",
            "|Arizona                                |\n",
            "|Iowa                                   |\n",
            "|Massachusetts                          |\n",
            "|Kentucky                               |\n",
            "|Louisiana                              |\n",
            "|Mississippi                            |\n",
            "|Tennessee                              |\n",
            "|New Hampshire                          |\n",
            "|Indiana                                |\n",
            "|Florida                                |\n",
            "|Idaho                                  |\n",
            "|South Carolina                         |\n",
            "|South Dakota                           |\n",
            "|California                             |\n",
            "|New York                               |\n",
            "|Wisconsin                              |\n",
            "|Maine                                  |\n",
            "+---------------------------------------+\n",
            "only showing top 50 rows\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        }
      ],
      "source": [
        "# Define categorical column(s) to inspect\n",
        "categorical_cols = [\n",
        "    \"REMOTE_TYPE_NAME\", \"COMPANY_IS_STAFFING\", \"IS_INTERNSHIP\", \"EMPLOYMENT_TYPE_NAME\", \"MIN_EDULEVELS_NAME\", \"STATE_NAME\"\n",
        "]\n",
        "\n",
        "# Display distinct values for each categorical column\n",
        "for colname in categorical_cols:\n",
        "    print(f\"\\n---- {colname} ----\")\n",
        "    df_eda.select(colname).distinct().show(50, truncate=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+------+-----------+---------+--------------------+--------+-------------------+-------------+----------------+----------------------+-------------------+----------+\n",
            "|SALARY|SALARY_FROM|SALARY_TO|MIN_YEARS_EXPERIENCE|DURATION|COMPANY_IS_STAFFING|IS_INTERNSHIP|REMOTE_TYPE_NAME|EMPLOYMENT_TYPE_NAME  |MIN_EDULEVELS_NAME |STATE_NAME|\n",
            "+------+-----------+---------+--------------------+--------+-------------------+-------------+----------------+----------------------+-------------------+----------+\n",
            "|NULL  |NULL       |NULL     |2                   |6       |false              |false        |On Premise      |Full-time (> 32 hours)|Bachelor's degree  |Arkansas  |\n",
            "|NULL  |NULL       |NULL     |3                   |NULL    |true               |false        |Remote          |Full-time (> 32 hours)|No Education Listed|Maine     |\n",
            "|NULL  |NULL       |NULL     |5                   |35      |false              |false        |On Premise      |Full-time (> 32 hours)|Bachelor's degree  |Texas     |\n",
            "|NULL  |NULL       |NULL     |3                   |48      |false              |false        |On Premise      |Full-time (> 32 hours)|No Education Listed|Arizona   |\n",
            "|92500 |35000      |150000   |NULL                |15      |false              |false        |On Premise      |Part-time / full-time |No Education Listed|California|\n",
            "+------+-----------+---------+--------------------+--------+-------------------+-------------+----------------+----------------------+-------------------+----------+\n",
            "only showing top 5 rows\n"
          ]
        }
      ],
      "source": [
        "# For REMOTE_TYPE_NAME replace Remote with Remote, [None] with undefined, Not Remote with On Premise, Hybrid Remote with Hybrid, and Null with On Premise \n",
        "\n",
        "from pyspark.sql.functions import col, when\n",
        "\n",
        "df_eda = df_eda.withColumn(\n",
        "    \"REMOTE_TYPE_NAME\",\n",
        "    when(col(\"REMOTE_TYPE_NAME\") == \"Remote\", \"Remote\")\n",
        "    .when(col(\"REMOTE_TYPE_NAME\") == \"[None]\", \"On Premise\")\n",
        "    .when(col(\"REMOTE_TYPE_NAME\") == \"Not Remote\", \"On Premise\")\n",
        "    .when(col(\"REMOTE_TYPE_NAME\") == \"Hybrid Remote\", \"Hybrid\")\n",
        "    .when(col(\"REMOTE_TYPE_NAME\").isNull(), \"On Premise\")\n",
        "    .otherwise(col(\"REMOTE_TYPE_NAME\"))\n",
        ")\n",
        "\n",
        "# create a temporary SQL view if using Spark SQL queries later\n",
        "df_eda.createOrReplaceTempView(\"df_eda\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pyspark.sql.functions import countDistinct\n",
        "\n",
        "# Count number of unique values per column\n",
        "df_eda.select([\n",
        "    countDistinct(c).alias(c + \"_nunique\")\n",
        "    for c in df_eda.columns\n",
        "]).show(truncate=False)\n",
        "\n",
        "categorical_cols = [\n",
        "    \"STATE_NAME\", \"REMOTE_TYPE_NAME\", \"EMPLOYMENT_TYPE_NAME\",\n",
        "    \"MIN_EDULEVELS_NAME\", \"MAX_EDULEVELS_NAME\",\n",
        "    \"COMPANY_IS_STAFFING\", \"IS_INTERNSHIP\"\n",
        "]\n",
        "\n",
        "for colname in categorical_cols:\n",
        "    print(f\"\\n---- {colname} ----\")\n",
        "    df_eda.select(colname).distinct().show(50, truncate=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pyspark.sql.functions import col, when\n",
        "\n",
        "# Calculate median of the DURATION column\n",
        "median_duration = df_eda.approxQuantile(\"DURATION\", [0.5], 0.01)[0]\n",
        "\n",
        "# Fill missing DURATION values with the median (assume 30 if needed)\n",
        "df_eda = df_eda.withColumn(\n",
        "    \"DURATION\",\n",
        "    when(col(\"DURATION\").isNull(), median_duration).otherwise(col(\"DURATION\"))\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import hvplot.pandas  # needed to enable hvplot on Pandas DataFrames\n",
        "from pyspark.sql.functions import col, when, trim, length, sum as spark_sum\n",
        "\n",
        "# Calculate missing value counts for each column in df_eda\n",
        "missing_df = df_eda.select([\n",
        "    spark_sum(\n",
        "        when(col(c).isNull() | (length(trim(col(c))) == 0), 1).otherwise(0)\n",
        "    ).alias(c)\n",
        "    for c in df_eda.columns\n",
        "])\n",
        "\n",
        "# Convert to pandas for visualization\n",
        "missing_pd = missing_df.toPandas().T.reset_index()\n",
        "missing_pd.columns = [\"column\", \"missing_count\"]\n",
        "\n",
        "# Get total number of rows in original df\n",
        "total_rows = df_eda.count()\n",
        "\n",
        "# Calculate missing percentage\n",
        "missing_pd[\"missing_pct\"] = 100 * missing_pd[\"missing_count\"] / total_rows\n",
        "\n",
        "# Plot missing values using hvplot\n",
        "missing_pd.sort_values(\"missing_pct\", ascending=False).hvplot.bar(\n",
        "    x=\"column\", y=\"missing_pct\", rot=90,\n",
        "    title=\"Percentage of Missing Values by Column\",\n",
        "    height=600, width=900,\n",
        "    ylabel=\"Missing Percentage (%)\", xlabel=\"Features\"\n",
        ").opts(xrotation=45)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python (ad688-venv)",
      "language": "python",
      "name": "ad688-venv",
      "path": "/usr/share/jupyter/kernels/python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
